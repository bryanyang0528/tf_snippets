{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saves and restores variables.\n",
      "\n",
      "  See @{$variables$Variables}\n",
      "  for an overview of variables, saving and restoring.\n",
      "\n",
      "  The `Saver` class adds ops to save and restore variables to and from\n",
      "  *checkpoints*.  It also provides convenience methods to run these ops.\n",
      "\n",
      "  Checkpoints are binary files in a proprietary format which map variable names\n",
      "  to tensor values.  The best way to examine the contents of a checkpoint is to\n",
      "  load it using a `Saver`.\n",
      "\n",
      "  Savers can automatically number checkpoint filenames with a provided counter.\n",
      "  This lets you keep multiple checkpoints at different steps while training a\n",
      "  model.  For example you can number the checkpoint filenames with the training\n",
      "  step number.  To avoid filling up disks, savers manage checkpoint files\n",
      "  automatically. For example, they can keep only the N most recent files, or\n",
      "  one checkpoint for every N hours of training.\n",
      "\n",
      "  You number checkpoint filenames by passing a value to the optional\n",
      "  `global_step` argument to `save()`:\n",
      "\n",
      "  ```python\n",
      "  saver.save(sess, 'my-model', global_step=0) ==> filename: 'my-model-0'\n",
      "  ...\n",
      "  saver.save(sess, 'my-model', global_step=1000) ==> filename: 'my-model-1000'\n",
      "  ```\n",
      "\n",
      "  Additionally, optional arguments to the `Saver()` constructor let you control\n",
      "  the proliferation of checkpoint files on disk:\n",
      "\n",
      "  * `max_to_keep` indicates the maximum number of recent checkpoint files to\n",
      "    keep.  As new files are created, older files are deleted.  If None or 0,\n",
      "    all checkpoint files are kept.  Defaults to 5 (that is, the 5 most recent\n",
      "    checkpoint files are kept.)\n",
      "\n",
      "  * `keep_checkpoint_every_n_hours`: In addition to keeping the most recent\n",
      "    `max_to_keep` checkpoint files, you might want to keep one checkpoint file\n",
      "    for every N hours of training.  This can be useful if you want to later\n",
      "    analyze how a model progressed during a long training session.  For\n",
      "    example, passing `keep_checkpoint_every_n_hours=2` ensures that you keep\n",
      "    one checkpoint file for every 2 hours of training.  The default value of\n",
      "    10,000 hours effectively disables the feature.\n",
      "\n",
      "  Note that you still have to call the `save()` method to save the model.\n",
      "  Passing these arguments to the constructor will not save variables\n",
      "  automatically for you.\n",
      "\n",
      "  A training program that saves regularly looks like:\n",
      "\n",
      "  ```python\n",
      "  ...\n",
      "  # Create a saver.\n",
      "  saver = tf.train.Saver(...variables...)\n",
      "  # Launch the graph and train, saving the model every 1,000 steps.\n",
      "  sess = tf.Session()\n",
      "  for step in xrange(1000000):\n",
      "      sess.run(..training_op..)\n",
      "      if step % 1000 == 0:\n",
      "          # Append the step number to the checkpoint name:\n",
      "          saver.save(sess, 'my-model', global_step=step)\n",
      "  ```\n",
      "\n",
      "  In addition to checkpoint files, savers keep a protocol buffer on disk with\n",
      "  the list of recent checkpoints. This is used to manage numbered checkpoint\n",
      "  files and by `latest_checkpoint()`, which makes it easy to discover the path\n",
      "  to the most recent checkpoint. That protocol buffer is stored in a file named\n",
      "  'checkpoint' next to the checkpoint files.\n",
      "\n",
      "  If you create several savers, you can specify a different filename for the\n",
      "  protocol buffer file in the call to `save()`.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(tf.train.Saver.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN\n",
    "def build_graph(graph):\n",
    "    with graph.as_default():\n",
    "        x_ = tf.placeholder(tf.float32, shape=[None, 784], name=\"x_\")\n",
    "        y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"y_\")\n",
    "\n",
    "        W_h = tf.Variable(np.random.randn(784, 100), \n",
    "                          dtype=tf.float32, \n",
    "                          name=\"W_h\")\n",
    "        b_h = tf.Variable(np.zeros(100), \n",
    "                          dtype=tf.float32,\n",
    "                          name=\"b_h\")\n",
    "        z_h = tf.matmul(x_, W_h) + b_h\n",
    "        layer_h = tf.nn.sigmoid(z_h)\n",
    "\n",
    "        W_o = tf.Variable(np.random.randn(100, 10),\n",
    "                          dtype=tf.float32,\n",
    "                          name=\"W_o\")\n",
    "        b_o = tf.Variable(np.random.randn(10),\n",
    "                          dtype=tf.float32,\n",
    "                          name=\"b_o\")\n",
    "        z_o = tf.matmul(layer_h, W_o) + b_o\n",
    "        y = tf.nn.softmax(z_o)\n",
    "        predict = tf.arg_max(y, 1)\n",
    "\n",
    "        loss = - tf.reduce_mean(y_*tf.log(y))\n",
    "        train_op = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "        # saver to save session\n",
    "        saver = tf.train.Saver() \n",
    "    return x_, y_, predict, loss, train_op, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def comput_accuracy(y1, y2):\n",
    "    return 100*(y1 == y2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000: loss 0.24087940156459808, acc 46.01\n",
      "Iteration 2000: loss 0.15155558288097382, acc 58.220000000000006\n",
      "Iteration 3000: loss 0.1389244645833969, acc 65.16999999999999\n",
      "Iteration 4000: loss 0.0990942195057869, acc 69.37\n",
      "Iteration 5000: loss 0.09231088310480118, acc 72.64\n",
      "Iteration 6000: loss 0.07886165380477905, acc 74.89\n",
      "Iteration 7000: loss 0.08633018285036087, acc 76.33\n",
      "Iteration 8000: loss 0.06446634232997894, acc 77.69\n",
      "Iteration 9000: loss 0.05860651284456253, acc 78.81\n",
      "Iteration 10000: loss 0.08533971756696701, acc 79.75999999999999\n",
      "Iteration 11000: loss 0.055535003542900085, acc 80.61\n",
      "Iteration 12000: loss 0.07122772186994553, acc 81.19\n",
      "Iteration 13000: loss 0.056912731379270554, acc 81.96\n",
      "Iteration 14000: loss 0.06299170851707458, acc 82.52000000000001\n",
      "Iteration 15000: loss 0.05374893546104431, acc 83.12\n",
      "Iteration 16000: loss 0.05282098427414894, acc 83.57\n",
      "Iteration 17000: loss 0.05982606112957001, acc 83.87\n",
      "Iteration 18000: loss 0.051524125039577484, acc 84.17999999999999\n",
      "Iteration 19000: loss 0.04999775066971779, acc 84.57000000000001\n",
      "Iteration 20000: loss 0.038183342665433884, acc 84.75\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "n_iteration = 20000\n",
    "\n",
    "graph = tf.Graph()\n",
    "x_, y_, predict, loss, train_op, saver = build_graph(graph)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for step in range(n_iteration):\n",
    "        train_images, train_labels = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {x_: train_images, \n",
    "                     y_:train_labels}\n",
    "        _, l = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "    \n",
    "        if (step+1) % 1000 == 0:\n",
    "            pred = sess.run(predict, feed_dict={x_:mnist.test.images,\n",
    "                                                y_:mnist.test.labels})\n",
    "            acc = comput_accuracy(pred, np.argmax(mnist.test.labels, 1))\n",
    "            print(\"Iteration {}: loss {}, acc {}\".format(step+1, l, acc))\n",
    "    saver.save(sess, \"models/example_save_session.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/example_save_session.ckpt\n",
      "restored accuracy: 84.75\n"
     ]
    }
   ],
   "source": [
    "restore_graph = tf.Graph()\n",
    "x_, y_, predict, _, _, saver = build_graph(restore_graph)\n",
    "\n",
    "with tf.Session(graph=restore_graph) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, \"models/example_save_session.ckpt\")\n",
    "    \n",
    "    feed_dict = {x_:mnist.test.images,\n",
    "                 y_:mnist.test.labels}\n",
    "    pred = sess.run(predict, feed_dict=feed_dict)\n",
    "    acc = comput_accuracy(pred, np.argmax(mnist.test.labels, 1))\n",
    "    print(\"restored accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
